# Introduction

LEGENT is a platform for embodied agent.

One day, robots will perceive the environment as we do, communicate with us through natural language and help us with our tasks. The platform is dedicated to developing future robots that can chat, see, and act from virtual world to real world, powered by large models.
We aspire to democratize the research in this field for anyone interested. LEGENT is a pioneering full-stack open-source solution combining large models with embodied agents, prioritizing ease of use and scalability. The platform focuses on developing the following functionalities:

1. An easy-to-use environment that simulates a physical world, where an agent can interact with humans through language, receive egocentric vision, and perform physical actions.

2. Automated generation of training data, including the generation of scenes, tasks, and ground truth actions. **We aspire to exploit supervision from simulated worlds at scale**. The design of the platform is tailored to facilitate the development of generalizable embodied agents based on large models.

3. Implementation of important models for embodied agents, such as [vision-language-action](https://arxiv.org/abs/2307.15818) models.

!!! warning "Important Note"
    
    LEGENT is currently organizing code and documents, as well as carrying out necessary bug fixes and improvements to existing features. It will be more convenient to use once this process is complete. If you want a more stable version, please stay tuned!

!!! Note
    
    LEGENT is in the early stages of development, so issues and shortcomings are inevitable. We appreciate your constructive feedback and will address problems as quickly as possible.